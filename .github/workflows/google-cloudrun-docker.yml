# This workflow build and push a Docker container to Google Artifact Registry
# and deploy it on Cloud Run when a commit is pushed to the "main" branch.
#
# To configure this workflow:
#
# 1. Enable the following Google Cloud APIs:
#
#    - Artifact Registry (artifactregistry.googleapis.com)
#    - Cloud Run (run.googleapis.com)
#    - IAM Credentials API (iamcredentials.googleapis.com)
#
#    You can learn more about enabling APIs at
#    https://support.google.com/googleapi/answer/6158841.
#
# 2. Create and configure a Workload Identity Provider for GitHub:
#    https://github.com/google-github-actions/auth#preferred-direct-workload-identity-federation.
#
#    Depending on how you authenticate, you will need to grant an IAM principal
#    permissions on Google Cloud:
#
#    - Artifact Registry Administrator (roles/artifactregistry.admin)
#    - Cloud Run Developer (roles/run.developer)
#
#    You can learn more about setting IAM permissions at
#    https://cloud.google.com/iam/docs/manage-access-other-resources
#
# 3. Change the values in the "env" block to match your values.

name: 'Build and Deploy to Cloud Run'

on:
  push:
    branches:
      - main
  workflow_dispatch:
    inputs:
      image_tag:
        description: "Image tag"
        required: false
        default: "v1"
      model_gcs_uri:
        description: "GCS URI to model tar.gz (e.g. gs://bucket/models/kcbert_model.tar.gz). If omitted, the workflow will auto-detect via secret/var or latest object in a bucket."
        required: false
      api_key:
        description: "Optional API key to inject (X-API-Key)"
        required: false
      cors_origins:
        description: "Optional comma-separated CORS origins for /predict"
        required: false
      threshold_certain:
        description: "Optional MALICIOUS_THRESHOLD_CERTAIN (e.g. 0.999)"
        required: false
      threshold_ambiguous:
        description: "Optional MALICIOUS_THRESHOLD_AMBIGUOUS (e.g. 0.9)"
        required: false

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  REGION: 'us-west1'
  SERVICE: 'toxic-filter'
  REPO: toxic-filter
  WORKLOAD_IDENTITY_PROVIDER: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}

jobs:
  deploy:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # Configure Workload Identity Federation and generate an access token.
      #
      # See https://github.com/google-github-actions/auth for more options,
      # including authenticating via a JSON credentials file.
      - id: auth
        name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v3
        with:
          workload_identity_provider: ${{ env.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v3

      - name: Set project
        run: |
          gcloud config set project "${{ env.PROJECT_ID }}"
          gcloud config set run/region "${{ env.REGION }}"

      - name: Enable required APIs
        run: |
          gcloud services enable \
            run.googleapis.com \
            artifactregistry.googleapis.com \
            cloudbuild.googleapis.com \
            iamcredentials.googleapis.com

      - name: Ensure Artifact Registry repo
        run: |
          set -euo pipefail
          gcloud artifacts repositories describe "${{ env.REPO }}" \
            --location "${{ env.REGION }}" >/dev/null 2>&1 || \
          gcloud artifacts repositories create "${{ env.REPO }}" \
            --repository-format=docker \
            --location "${{ env.REGION }}"
      
      - name: Build and Push image (Cloud Build)
        env:
          IMAGE_TAG: ${{ github.event.inputs.image_tag || 'v1' }}
          # Primary source: manual input; fallback to secrets/vars
          MODEL_GCS_URI_IN: ${{ github.event.inputs.model_gcs_uri }}
          MODEL_GCS_URI_SECRET: ${{ secrets.MODEL_GCS_URI }}
          MODEL_GCS_URI_VAR: ${{ vars.MODEL_GCS_URI }}
          # Optional: bucket/prefix to auto-discover latest tar.gz
          MODEL_GCS_BUCKET: ${{ secrets.MODEL_GCS_BUCKET || vars.MODEL_GCS_BUCKET }}
          MODEL_GCS_PREFIX: ${{ secrets.MODEL_GCS_PREFIX || vars.MODEL_GCS_PREFIX || 'models' }}
          # Optional: direct HTTP(S) tarball URL
          MODEL_TARBALL_URL: ${{ secrets.MODEL_TARBALL_URL || vars.MODEL_TARBALL_URL }}
        run: |
          set -euo pipefail

          # Resolve MODEL_GCS_URI from multiple sources
          MODEL_GCS_URI=${MODEL_GCS_URI_IN:-}
          if [[ -z "${MODEL_GCS_URI}" ]]; then
            MODEL_GCS_URI=${MODEL_GCS_URI_SECRET:-}
          fi
          if [[ -z "${MODEL_GCS_URI}" ]]; then
            MODEL_GCS_URI=${MODEL_GCS_URI_VAR:-}
          fi

          # If still empty, try file-based configuration
          if [[ -z "${MODEL_GCS_URI}" ]]; then
            if [[ -f .model_gcs_uri ]]; then
              MODEL_GCS_URI=$(< .model_gcs_uri)
            elif [[ -f .github/model_gcs_uri ]]; then
              MODEL_GCS_URI=$(< .github/model_gcs_uri)
            fi
          fi

          # If still empty and BUCKET provided, auto-discover latest *.tar.gz under prefix
          if [[ -z "${MODEL_GCS_URI}" && -n "${MODEL_GCS_BUCKET:-}" ]]; then
            echo "Attempting to auto-detect latest tarball in gs://${MODEL_GCS_BUCKET}/${MODEL_GCS_PREFIX}/*.tar.gz" >&2
            # gsutil ls -l prints lines with timestamps; filter valid object lines and pick the latest by timestamp
            DETECTED=$(gsutil ls -l "gs://${MODEL_GCS_BUCKET}/${MODEL_GCS_PREFIX}/*.tar.gz" 2>/dev/null \
              | awk '/^\s*[0-9]+\s+\S+\s+gs:\/\// {print $0}' \
              | sort -k2,3 \
              | awk '{print $NF}' \
              | tail -n1 || true)
            if [[ -n "${DETECTED}" ]]; then
              MODEL_GCS_URI="$DETECTED"
              echo "Auto-detected MODEL_GCS_URI=${MODEL_GCS_URI}" >&2
            fi
          fi

          # If still empty but a direct URL is provided, we'll use curl in Cloud Build step
          if [[ -z "${MODEL_GCS_URI}" && -z "${MODEL_TARBALL_URL:-}" ]]; then
            echo "❌ MODEL_GCS_URI is missing. Provide via input, secret/var, .model_gcs_uri file, set MODEL_GCS_BUCKET for auto-detect, or provide MODEL_TARBALL_URL."
            exit 1
          fi

          IMAGE_URI="${{ env.REGION }}-docker.pkg.dev/${PROJECT_ID}/${{ env.REPO }}/${{ env.SERVICE }}:${IMAGE_TAG}"
          echo "IMAGE_URI=${IMAGE_URI}" >> "$GITHUB_ENV"

          # Generate Cloud Build config that pulls the model from GCS into the build context, then builds & pushes.
          cat > cloudbuild.yaml <<EOF
          steps:
          - name: 'gcr.io/cloud-builders/gsutil'
            id: 'fetch-model-gcs'
            entrypoint: 'bash'
            args:
            - -c
            - |
              set -euo pipefail
              if [[ -n "${MODEL_GCS_URI}" ]]; then
                echo "Fetching from GCS: ${MODEL_GCS_URI}"
                gsutil cp "${MODEL_GCS_URI}" kcbert_model.tar.gz
              elif [[ -n "${MODEL_TARBALL_URL}" ]]; then
                echo "Fetching from URL: ${MODEL_TARBALL_URL}"
                curl -fSL "${MODEL_TARBALL_URL}" -o kcbert_model.tar.gz
              else
                echo 'No MODEL_GCS_URI or MODEL_TARBALL_URL provided' >&2
                exit 1
              fi
          - name: 'gcr.io/cloud-builders/docker'
            args: ['build', '-f', 'Dockerfile', '-t', '${IMAGE_URI}', '.']
          images:
          - '${IMAGE_URI}'
          EOF

          # Submit build without streaming logs (avoids VPC-SC/logs-bucket restrictions)
          # Capture BUILD_ID from the creation message and poll for completion.
          CREATE_OUT=$(gcloud builds submit --config=cloudbuild.yaml --project "${PROJECT_ID}" --async .)
          echo "$CREATE_OUT"
          BUILD_ID=$(printf "%s" "$CREATE_OUT" | grep -oE 'builds/[0-9a-f-]+' | sed 's|builds/||' | head -n1)
          if [[ -z "${BUILD_ID}" ]]; then
            echo "❌ Failed to obtain Cloud Build ID" >&2
            exit 1
          fi
          echo "Cloud Build ID: ${BUILD_ID}"
          echo "CLOUD_BUILD_ID=${BUILD_ID}" >> "$GITHUB_ENV"

          # Poll build status until completion without streaming logs
          BUILD_LINK="https://console.cloud.google.com/cloud-build/builds/${BUILD_ID}?project=${PROJECT_ID}"
          echo "Build link: ${BUILD_LINK}"
          while true; do
            STATUS=$(gcloud builds describe "$BUILD_ID" --project "${PROJECT_ID}" --format='value(status)') || STATUS="UNKNOWN"
            echo "Cloud Build status: $STATUS"
            case "$STATUS" in
              SUCCESS)
                break
                ;;
              FAILURE|CANCELLED|TIMEOUT|EXPIRED)
                echo "❌ Cloud Build ended with status: $STATUS" >&2
                exit 1
                ;;
            esac
            sleep 5
          done

      - name: Deploy to Cloud Run
        env:
          IMAGE_URI: ${{ env.IMAGE_URI }}
          # Optional inputs/secrets with fallback
          API_KEY_IN: ${{ github.event.inputs.api_key || secrets.API_KEY }}
          CORS_ORIGINS_IN: ${{ github.event.inputs.cors_origins }}
          THRESHOLD_CERTAIN_IN: ${{ github.event.inputs.threshold_certain }}
          THRESHOLD_AMBIGUOUS_IN: ${{ github.event.inputs.threshold_ambiguous }}
        run: |
          set -euo pipefail

          # Build env var list conditionally
          ENV_VARS="PORT=9090"
          if [[ -n "${API_KEY_IN:-}" ]]; then
            ENV_VARS+=",API_KEY=${API_KEY_IN}"
          fi
          if [[ -n "${CORS_ORIGINS_IN:-}" ]]; then
            ENV_VARS+=",CORS_ORIGINS=${CORS_ORIGINS_IN}"
          fi
          if [[ -n "${THRESHOLD_CERTAIN_IN:-}" ]]; then
            ENV_VARS+=",MALICIOUS_THRESHOLD_CERTAIN=${THRESHOLD_CERTAIN_IN}"
          fi
          if [[ -n "${THRESHOLD_AMBIGUOUS_IN:-}" ]]; then
            ENV_VARS+=",MALICIOUS_THRESHOLD_AMBIGUOUS=${THRESHOLD_AMBIGUOUS_IN}"
          fi

          gcloud run deploy "${{ env.SERVICE }}" \
            --image "${IMAGE_URI}" \
            --region "${{ env.REGION }}" \
            --platform managed \
            --allow-unauthenticated \
            --cpu=1 \
            --memory=1Gi \
            --concurrency=80 \
            --min-instances=0 \
            --max-instances=3 \
            --port=9090 \
            --ingress=all \
            --labels=deployed_by=github-actions,commit_sha=${{ github.sha }} \
            --update-env-vars "${ENV_VARS}"

      - name: Get service URL
        id: url
        run: |
          URL="$(gcloud run services describe '${{ env.SERVICE }}' --region='${{ env.REGION }}' --format='value(status.url)')"
          echo "service_url=${URL}" >> "$GITHUB_OUTPUT"

      - name: Post deployment summary
        run: |
          echo "✅ Deployed **${{ env.SERVICE }}** to **${{ env.REGION }}**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Image: \`${{ env.IMAGE_URI }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- URL: ${{ steps.url.outputs.service_url }}" >> $GITHUB_STEP_SUMMARY
          echo "- Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
